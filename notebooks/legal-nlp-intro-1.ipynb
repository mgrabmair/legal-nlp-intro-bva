{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import random\n",
    "import re\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_path = '../data/20171208_luima.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = json.load(open(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['documents', 'types', 'annotations', 'objects'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_id', 'name', 'plainText'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['documents'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '5a0dc3747a75cf2bafc0db8d',\n",
       " 'attributes': [],\n",
       " 'document': '59d3ed9544a09d7f8e4763d9',\n",
       " 'end': 211,\n",
       " 'owner': '58a0bf4f8424bd4f65e2be57',\n",
       " 'start': 202,\n",
       " 'type': '5a0ca67d7a75cf2bafc0d50d'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '59d3ec8e44a09d7f8e4763c5',\n",
       " 'attributes': [],\n",
       " 'isA': '58781cf945f90f3bfc5cba7d',\n",
       " 'name': 'Citation'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['types'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# move data into id-keyed dictionary\n",
    "documents = {d['_id']: d for d in data['documents']}\n",
    "types = {t['_id']: t for t in data['types']}\n",
    "# move annotations into list\n",
    "annotations = data['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get all sentences assuming every annotation is a sentence\n",
    "def make_sentence_data(documents, types, annotations):\n",
    "    sentence_data = []\n",
    "    for a in annotations:\n",
    "        start = a['start']\n",
    "        end = a['end']\n",
    "        document_txt = documents[a['document']]['plainText']\n",
    "        atype = a['type']\n",
    "        sentence_txt = document_txt[start:end]\n",
    "        sd = {'txt': sentence_txt,\n",
    "              'type': types[atype]['name']}\n",
    "        sentence_data.append(sd)\n",
    "    return sentence_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sentence_data = make_sentence_data(documents, types, annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'txt': 'However, the clinical evidence of record fails to show that the Veteran manifested arthritis to a degree of 10 percent within the one year following his active duty service discharge in August 1962.', 'type': 'EvidenceBasedReasoning'}\n",
      "{'txt': \"The examiner did not have any of the Veteran's medical records and offered no opinion as to a medical nexus between the veteran's current left knee disability and his in-service injury.\", 'type': 'Evidence'}\n",
      "{'txt': 'Hence, the Veteran is not shown to be prejudiced by the timing of this notice.', 'type': 'EvidenceBasedReasoning'}\n"
     ]
    }
   ],
   "source": [
    "# look at examples\n",
    "for _ in range(3):\n",
    "    print(random.choice(sentence_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "805"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Tokenizing text into individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tokenize(txt):\n",
    "    \n",
    "    # split sentences on one or more whitespace characters\n",
    "    dirty_tokens = re.split(' +', txt)\n",
    "    \n",
    "    # remove all non-alphanumeric characters and lowercase everything\n",
    "    clean_tokens = []\n",
    "    for t in dirty_tokens:\n",
    "        clean_tokens.append(re.sub(r'\\W', '', t).lower())\n",
    "    \n",
    "    # remove empty tokens\n",
    "    if '' in clean_tokens:\n",
    "        clean_tokens.remove('')\n",
    "    \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# demo/test the tokenizer\n",
    "#tokenize(\"Rather, the report of the Veteran's February 2006 VA examination stated that Veteran did not meet the criteria for PTSD.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tokenize_sentence_data(sentence_data):\n",
    "    for s in sentence_data:\n",
    "        s['tokens'] = tokenize(s['txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tokenize_sentence_data(sentence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['the',\n",
       "  'board',\n",
       "  'has',\n",
       "  'first',\n",
       "  'considered',\n",
       "  'whether',\n",
       "  'service',\n",
       "  'connection',\n",
       "  'is',\n",
       "  'warranted',\n",
       "  'on',\n",
       "  'a',\n",
       "  'presumptive',\n",
       "  'basis'],\n",
       " 'txt': 'The Board has first considered whether service connection is warranted on a presumptive basis.',\n",
       " 'type': 'EvidenceBasedReasoning'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check post-tokenization\n",
    "random.choice(sentence_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Building a vocabulary list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_vocabulary(sentences_data):\n",
    "    vocabulary = set()\n",
    "    for sd in sentences_data:\n",
    "        vocabulary = vocabulary | set(tokenize(sd['txt']))\n",
    "    return sorted(list(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vocabulary = build_vocabulary(sentence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# look at vocabulary\n",
    "# vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test word\n",
    "vocabulary.index('veteran')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2092"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabulary size\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Featurizing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def featurize_sentence(s, vocabulary):\n",
    "    features = []\n",
    "    \n",
    "    # binary features\n",
    "    for v in vocabulary:\n",
    "        if v in s['tokens']:\n",
    "            features.append(1)\n",
    "        else:\n",
    "            features.append(0)\n",
    "    featurized = {'txt': s['txt'],\n",
    "                  'features': features,\n",
    "                  'target': s['type']}\n",
    "    return featurized\n",
    "    \n",
    "def featurize_sentence_data(sentence_data, vocabulary):\n",
    "    return list(map(lambda s: featurize_sentence(s, vocabulary), sentence_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sentence_data_featurized = featurize_sentence_data(sentence_data, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#random.choice(sentence_data_featurized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Splitting our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = [fs['features'] for fs in sentence_data_featurized]\n",
    "y = [fs['target'] for fs in sentence_data_featurized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training a decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dtc = tree.DecisionTreeClassifier(max_depth=12)\n",
    "clf = dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Citation', 'ConclusionOfLaw', 'Evidence', 'EvidenceBasedFinding',\n",
       "       'EvidenceBasedReasoning', 'Header', 'LegalPolicy', 'LegalRule',\n",
       "       'Procedure'],\n",
       "      dtype='<U22')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Output Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bva-single.pdf'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(clf,\n",
    "                                out_file=None,\n",
    "                                feature_names=vocabulary,\n",
    "                                class_names=clf.classes_,\n",
    "                                rounded=True, \n",
    "                                filled=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"bva-single\")\n",
    "#graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "              Citation       1.00      0.99      0.99        97\n",
      "       ConclusionOfLaw       0.92      0.61      0.73        18\n",
      "              Evidence       0.84      0.94      0.89       179\n",
      "  EvidenceBasedFinding       0.85      0.80      0.83        56\n",
      "EvidenceBasedReasoning       0.76      0.72      0.74        82\n",
      "                Header       1.00      0.43      0.60        54\n",
      "           LegalPolicy       1.00      0.50      0.67        12\n",
      "             LegalRule       0.92      0.88      0.90        78\n",
      "             Procedure       0.61      0.88      0.72        68\n",
      "\n",
      "           avg / total       0.86      0.84      0.83       644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, clf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "              Citation       1.00      0.97      0.98        31\n",
      "       ConclusionOfLaw       0.00      0.00      0.00         3\n",
      "              Evidence       0.67      0.79      0.72        38\n",
      "  EvidenceBasedFinding       0.14      0.09      0.11        11\n",
      "EvidenceBasedReasoning       0.44      0.29      0.35        24\n",
      "                Header       1.00      0.31      0.47        13\n",
      "           LegalPolicy       0.67      0.40      0.50         5\n",
      "             LegalRule       0.48      0.68      0.57        19\n",
      "             Procedure       0.50      0.76      0.60        17\n",
      "\n",
      "           avg / total       0.64      0.62      0.60       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict_sentence(txt, vocabulary, clf):\n",
    "    s = {'txt': txt,\n",
    "         'tokens': tokenize(txt),\n",
    "         'type': 'unknown'}\n",
    "    x = featurize_sentence(s, vocabulary)\n",
    "    label = clf.predict([x['features']])\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def false_predictions(sentence_data_featurized):\n",
    "    for s in sentence_data_featurized:\n",
    "        prediction = predict_sentence(s['txt'], vocabulary, clf)[0]\n",
    "        true_label = s['target']\n",
    "        if not prediction == true_label:\n",
    "            print(s['txt'] + ' - true: ' + str(true_label) + '; predicted: ' + str(prediction))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "false_predictions(sentence_data_featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_sentence(\"The requirements for service connection have been met.\", vocabulary, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
