{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import random\n",
    "import re\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_path = '../data/20171208_luima.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = json.load(open(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['documents', 'types', 'annotations', 'objects'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_id', 'name', 'plainText'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['documents'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '5a0dc3747a75cf2bafc0db8d',\n",
       " 'attributes': [],\n",
       " 'document': '59d3ed9544a09d7f8e4763d9',\n",
       " 'end': 211,\n",
       " 'owner': '58a0bf4f8424bd4f65e2be57',\n",
       " 'start': 202,\n",
       " 'type': '5a0ca67d7a75cf2bafc0d50d'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '59d3ec8e44a09d7f8e4763c5',\n",
       " 'attributes': [],\n",
       " 'isA': '58781cf945f90f3bfc5cba7d',\n",
       " 'name': 'Citation'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['types'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# move data into id-keyed dictionary\n",
    "documents = {d['_id']: d for d in data['documents']}\n",
    "types = {t['_id']: t for t in data['types']}\n",
    "# move annotations into list\n",
    "annotations = data['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get all sentences assuming every annotation is a sentence\n",
    "def make_sentence_data(documents, types, annotations):\n",
    "    sentence_data = []\n",
    "    for a in annotations:\n",
    "        start = a['start']\n",
    "        end = a['end']\n",
    "        document_txt = documents[a['document']]['plainText']\n",
    "        atype = a['type']\n",
    "        sentence_txt = document_txt[start:end]\n",
    "        sd = {'txt': sentence_txt,\n",
    "              'type': types[atype]['name']}\n",
    "        sentence_data.append(sd)\n",
    "    return sentence_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sentence_data = make_sentence_data(documents, types, annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'txt': \"However, when the record contains a recent diagnosis of disability prior to the Veteran's filing of a claim for benefits based on that disability, the report of the diagnosis is relevant evidence that the Board must address in determining whether a current disability existed at the time the claim was filed or during its pendency.\", 'type': 'LegalRule'}\n",
      "{'txt': \"This case was previously before the Board in November 2010, when it remanded the Veteran's claim in order to solicit additional information from the Veteran regarding a psychological evaluation completed in conjunction with a domestic dispute in May 1993.\", 'type': 'Procedure'}\n",
      "{'txt': 'Dingess/Hartman v. \\nNicholson, 19 Vet. App. 473 (2006); 38 U.S.C.A. §§ 5100, \\n5102, 5103, 5103A, 5106, 5107; 38 C.F.R. §§ 3.159, 3.326; see \\nalso Pelegrini v. Principi, 18 Vet. App. 112, 120-21 (2004) \\n(Pelegrini II).', 'type': 'Citation'}\n"
     ]
    }
   ],
   "source": [
    "# look at examples\n",
    "for _ in range(3):\n",
    "    print(random.choice(sentence_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "805"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Tokenizing text into individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tokenize(txt):\n",
    "    \n",
    "    # split sentences on one or more whitespace characters\n",
    "    dirty_tokens = re.split(' +', txt)\n",
    "    \n",
    "    # remove all non-alphanumeric characters and lowercase everything\n",
    "    clean_tokens = []\n",
    "    for t in dirty_tokens:\n",
    "        clean_tokens.append(re.sub(r'\\W', '', t).lower())\n",
    "    \n",
    "    # remove empty tokens\n",
    "    if '' in clean_tokens:\n",
    "        clean_tokens.remove('')\n",
    "    \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# demo/test the tokenizer\n",
    "#tokenize(\"Rather, the report of the Veteran's February 2006 VA examination stated that Veteran did not meet the criteria for PTSD.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tokenize_sentence_data(sentence_data):\n",
    "    for s in sentence_data:\n",
    "        s['tokens'] = tokenize(s['txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tokenize_sentence_data(sentence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# check post-tokenization\n",
    "#random.choice(sentence_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Building a vocabulary list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_vocabulary(sentences_data):\n",
    "    vocabulary = set()\n",
    "    for sd in sentences_data:\n",
    "        vocabulary = vocabulary | set(tokenize(sd['txt']))\n",
    "    return sorted(list(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vocabulary = build_vocabulary(sentence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# look at vocabulary\n",
    "# vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test word\n",
    "vocabulary.index('veteran')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2092"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabulary size\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Featurizing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def featurize_sentence(s, all_s, vocabulary):\n",
    "    features = []\n",
    "    \n",
    "    # binary features\n",
    "    for v in vocabulary:\n",
    "        if v in s['tokens']:\n",
    "            features.append(1)\n",
    "        else:\n",
    "            features.append(0)\n",
    "    featurized = {'features': features,\n",
    "                  'target': s['type']}\n",
    "    return featurized\n",
    "    \n",
    "def featurize_sentence_data(sentence_data, vocabulary):\n",
    "    return list(map(lambda s: featurize_sentence(s, sentence_data, vocabulary), sentence_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sentence_data_featurized = featurize_sentence_data(sentence_data, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#random.choice(sentence_data_featurized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Splitting our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = [fs['features'] for fs in sentence_data_featurized]\n",
    "y = [fs['target'] for fs in sentence_data_featurized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training a decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dtc = tree.DecisionTreeClassifier(max_depth=12)\n",
    "clf = dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Citation', 'ConclusionOfLaw', 'Evidence', 'EvidenceBasedFinding',\n",
       "       'EvidenceBasedReasoning', 'Header', 'LegalPolicy', 'LegalRule',\n",
       "       'Procedure'],\n",
       "      dtype='<U22')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bva-single.pdf'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(clf,\n",
    "                                out_file=None,\n",
    "                                feature_names=vocabulary,\n",
    "                                class_names=clf.classes_,\n",
    "                                rounded=True, \n",
    "                                filled=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"bva-single\")\n",
    "#graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "              Citation       1.00      0.99      0.99        97\n",
      "       ConclusionOfLaw       0.92      0.61      0.73        18\n",
      "              Evidence       0.84      0.94      0.89       179\n",
      "  EvidenceBasedFinding       0.82      0.80      0.81        56\n",
      "EvidenceBasedReasoning       0.78      0.72      0.75        82\n",
      "                Header       1.00      0.43      0.60        54\n",
      "           LegalPolicy       1.00      0.50      0.67        12\n",
      "             LegalRule       0.92      0.88      0.90        78\n",
      "             Procedure       0.61      0.88      0.72        68\n",
      "\n",
      "           avg / total       0.86      0.84      0.83       644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, clf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "              Citation       1.00      0.97      0.98        31\n",
      "       ConclusionOfLaw       0.00      0.00      0.00         3\n",
      "              Evidence       0.67      0.82      0.74        38\n",
      "  EvidenceBasedFinding       0.38      0.27      0.32        11\n",
      "EvidenceBasedReasoning       0.64      0.29      0.40        24\n",
      "                Header       1.00      0.31      0.47        13\n",
      "           LegalPolicy       0.67      0.40      0.50         5\n",
      "             LegalRule       0.48      0.68      0.57        19\n",
      "             Procedure       0.50      0.76      0.60        17\n",
      "\n",
      "           avg / total       0.68      0.64      0.63       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
